{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## Reference\n",
    "\n",
    "Abu-Mostafa, Learning from Data\n",
    "\n",
    "## Definitions\n",
    "\n",
    "(Mitchell, 1997) A machine *learns* if its *performance* (error) in executing some *task* (processing) gets batter with its *experience* (data).\n",
    "\n",
    "Machine learning applies to problems in which there exists a *pattern*.\n",
    "\n",
    "##### Learning Problem\n",
    "\n",
    "A learning problem consists of:\n",
    "\n",
    "- an *unknown function* $f: X \\rightarrow Y$ that takes an *input* set $X$ to an *output* set $Y$\n",
    "- a *data set* $D = \\{(x_i, y_i) \\in X \\times Y\\ :\\ y_i = f(x_i)\\}$\n",
    "- a *hypothesis set* of functions, $H$\n",
    "- a *learning algorithm* $A$ that uses $D$ to pick $g \\in H$ that best approximates $f$\n",
    "\n",
    "We call $\\{H, A\\}$ the *learning model*.\n",
    "\n",
    "##### Examples\n",
    "\n",
    "1. The input set $X$ can be a collection of fundamentals of some company, i.e., revenue, earnings, assets, liabilities, growth etc., and the output set $Y$ is its stock price \n",
    "(the month average). We might want to learn the function $f$ (if there is any) which predict the stock price based on the fundamentals.\n",
    "\n",
    "2. Our input set is the price variation of a stock in the last $n$ days, that is, $X=\\mathbb{R}^n$, and the output set is $\\{-1, 1\\}$, where $-1$ indicates that the stock will go down \n",
    "tomorrow, and \n",
    "$1$ that it will go up.\n",
    "\n",
    "\n",
    "## Classes of ML algorithms\n",
    "\n",
    "Supervised Learning $\\rightarrow D = \\{(\\text{input, output})\\}$\n",
    "\n",
    "Reinforcement Learning $\\rightarrow D = \\{(\\text{input, some output, output's score})\\}$\n",
    "\n",
    "Unsupervised Learning $\\rightarrow D = \\{(\\text{input})\\}$\n",
    "\n",
    "Here we deal mainly with supervised learning.\n",
    "\n",
    "The concept of \"learning from data\" englobes *machine learning*, which goal is to uncover patterns, *statistics*, tha aims to infere probability distributions from data and *data mining*, that is, data analysis. All three are closely related, but different.\n",
    "\n",
    "\n",
    "## Linear Classification Model: The Perceptron\n",
    "\n",
    "In the linear classification learning model, the hypothesis set consists of all functions\n",
    "\n",
    "$$ h(x) = sgn(w \\cdot x + b) $$\n",
    "\n",
    "with $w \\in \\mathbb{R}^n$. If we set $w_0 = b$ and $x_0 = 1$,\n",
    "\n",
    "$$ h(x) = sgn(w^T\\cdot x) $$\n",
    "\n",
    "with $x \\in X = \\{1\\} \\times \\mathbb{R}^d$, where $d$ is the dimension of the input space.\n",
    "\n",
    "We say that the input space is *linearly separable* if there exists $h$ such that $h(x_i)=y_i$ for any $(x_i, y_i) \\in D$.\n",
    "\n",
    "One example of a linear classification model is the Perceptron Learning Algorithm (PLA), described below:\n",
    "\n",
    "While there is any element in the data set at time $t$ such that $h(x(t)) \\neq y(t)$, update $w$ according to the rule\n",
    "\n",
    "$$ w(t+1) = w(t) + y(t)x(t) $$\n",
    "\n",
    "## Linear Models\n",
    "\n",
    "##### 1) Linear Classification Model\n",
    "The input space is $\\mathbb{R}^d$ and the output space is $Y = \\{+1, -1\\}$\n",
    "$$H = \\{h(x) = sgn(w\\cdot x) : w \\in \\mathbb{R}^{d+1} \\}$$\n",
    "where we set $X = \\{1\\} \\times \\R^d$\n",
    "\n",
    "Example: PLA\n",
    "\n",
    "Application: Handwritten digit recognition, credit approval\n",
    "\n",
    "\"Pocket PLA\": at every iteration, runs $w(t+1)$ over all $D$ and only updates $w(t)$ if it actually got better (more complex!)\n",
    "\n",
    "##### 2) Linear Regression Model\n",
    "\n",
    "Instead of output space $Y = \\{+1, -1\\}$, we let $Y = \\mathbb{R}$ and instead of $y = f(x)$, we have an *unknown target distribution* $P(x,y)$ that generates the data set points. The hypothesis set becomes $H = \\{h(x) = sgn(w\\cdot x) : w \\in \\mathbb{R}^{d+1} \\}$\n",
    "\n",
    "\"Linear\" here means that we assume that $P$ can be approximated by a linear function of the input.\n",
    "\n",
    "Example: Linear Regression Algorithm (LRA)\n",
    "\n",
    "We start by defining an error function\n",
    "\n",
    "$$ E(w) = \\frac{1}{N} \\sum_{n=1}^{N} (w \\cdot x_n - y_n)^2 $$\n",
    "\n",
    "where $(x_n,y_n) \\in D$ and $N$ is the size of $D$. We define the error this way because this function is always $\\geq 0$ and differentiable. But we could choose another $E(w)$ depending on the problem.\n",
    "\n",
    "Then we define $\\mathcal{X} \\in \\mathbb{R}^{N\\times(d+1)}$ and $\\mathcal{Y} \\in \\mathbb{R^N}$:\n",
    "\n",
    "$$ \\mathcal{X} = \\begin{pmatrix}- x_1 - \\\\ - x_2 -  \\\\ .\\\\.\\\\.\\\\- x_N - \\end{pmatrix} $$\n",
    "\n",
    "$$ \\mathcal{Y} =  \\begin{pmatrix} y_1 \\\\ y_2 \\\\ .\\\\.\\\\.\\\\ y_N \\end{pmatrix} $$\n",
    "\n",
    "Then $$E(w) = \\frac{1}{N}|| \\mathcal{X}w - \\mathcal{Y} ||^2$$\n",
    "\n",
    "The linear regression consists in minimizing this function, that is, finding\n",
    "\n",
    "$$ w^* = \\text{argmin}_{w \\in \\mathbb{R}^{d+1}} E(w) $$\n",
    "\n",
    "As shown in the reference, this has the following analytical solution:\n",
    "\n",
    "$$ w^{*} = \\mathcal{X}^\\dagger b $$\n",
    "$$ \\mathcal{X}^\\dagger = (\\mathcal{X}^T\\mathcal{X})^{-1}\\mathcal{X}^T $$\n",
    "\n",
    "where $\\mathcal{X}^\\dagger$ is called the \"pseudo-inverse\". Notice that linear regression can be used for classification:\n",
    "\n",
    "Make $Y = \\{+1, -1\\} \\rightarrow \\mathbb{R}$. Use linear regression so that $w\\cdot x_i \\approx y_i = \\pm 1$. Then $h(x_i)$ is likely to agree with $y_i$. This is useful for obtaining a good estimate for an initial $w$ in the PLA.\n",
    "\n",
    "##### 3) Logistic Regression Model\n",
    "\n",
    "The output space is $Y = [0,1]$, that is, the output is the probability for a binary event (for example, the probability of a digit being or not '1'). The hypothesis set is \n",
    "\n",
    "$$ H = \\{ h(x) = \\theta(w\\cdot x) : w \\in \\mathbb{R}^{d+1} \\} $$\n",
    "\n",
    "where $\\theta(s) = \\frac{e^s}{1+e^s}$. \n",
    "\n",
    "The target to be learned is the probability of a certain outcome of a binary event:\n",
    "\n",
    "$$ f(x) = P(y=+1| x) \\text{   so that   } P(y|x) = \\begin{cases} f(x)\\text{, for }y=+1\\\\ 1-f(x)\\text{, for }y =-1 \\end{cases}$$\n",
    "\n",
    "To find a learning algorithm, as before, we need to define an error function. In this model, the error function is based on the notion of *likelihood*. Likelihood expresses the probability of obtaining the dataset $D$ from the hypothesis $h(x)$. As\n",
    "\n",
    "$$ P(y|x) = \\begin{cases}h(x)\\text{ , if }y=+1\\\\1 - h(x)\\text{ , if }y=-1\\end{cases} = \\begin{cases}\\theta(w\\cdot x)\\text{ , if }y=+1\\\\\\theta(-w\\cdot x)\\text{ , if }y=-1\\end{cases} = \\theta(y w \\cdot x)$$\n",
    "\n",
    "where we have used $1 - \\theta(s) = \\theta(-s)$. The likelihood is $ \\prod_{i=1}^N P(y_i|x_i) $\n",
    "\n",
    "We wish to minimize the following error function:\n",
    "\n",
    "$$ E(w) = -\\frac{1}{N} \\ln \\Big(\\prod_i P(y_i|x_i)\\Big) = \\frac{1}{N} \\sum_i \\ln \\Big(\\frac{1}{P(y_i|x_i)}\\Big) = \\frac{1}{N} \\sum_i \\ln \\Big(\\frac{1}{\\theta(y_i w \\cdot x_i)}\\Big)$$\n",
    "\n",
    "This is also called the \"maximum likelihood\" method. Substituting the formula for $\\theta$:\n",
    "\n",
    "$$ E(w) = \\frac{1}{N} \\sum_i \\ln\\Big(1 + e^{-y_i w\\cdot x_i}\\Big) $$\n",
    "\n",
    "Notice that this error is small when $y_i w \\cdot x_i >> 0$. Now, instead of making $\\nabla E(w) = 0$, we will use a new algorithm, the Gradient Descent (GD):\n",
    "\n",
    "At each iteration, we update w according to \n",
    "\n",
    "$$ w(t+1) = w(t) - \\eta \\nabla E(w(t)) $$\n",
    "\n",
    "in general we pick $\\eta \\sim 1$. The gradient is\n",
    "\n",
    "$$ \\nabla E (w) = -\\frac{1}{N} \\sum_i \\frac{y_i x_i}{1 + e^{-y_i w \\cdot x_i}} $$\n",
    "\n",
    "The initial weight $w(0)$ can be chosen randomly, and the termination criteria can be set by a maximum value of $t$, a threshold for $||\\nabla E||$ or even for $||E||$ itself.\n",
    "\n",
    "An alternative to GD is the Stochastic Gradient Descent (SGD). In it, instead of calculating the gradient using all $N$ points of the data set, at each iteration we pick a point $(x_i, y_i)$ uniformly at random and use it to update the weights as\n",
    "\n",
    "$$w(t+1) = w(t) - \\eta \\frac{y_ix_i}{1 + e^{-y_i w \\cdot x_i}}$$\n",
    "\n",
    "This works because the expected value of the gradient change over the a uniform distribution would be $- \\eta\\frac{1}{N}\\sum_i \\frac{y_ix_i}{1 + e^{-y_i w \\cdot x_i}}$ (exactly the same as in GD), so on average the descent proceeds in the right direction.\n",
    "\n",
    "## Nonlinear Transformations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
